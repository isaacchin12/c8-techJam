**1. Account Creation Restrictions (Effective January 1, 2024):**

* **Age Verification Required:** Platforms must implement reasonable measures to verify the age of users attempting to create accounts. This is a *huge* shift.
* **No Under 16:**  It’s illegal for a platform to allow a person under the age of 16 to create an account.
* **Enhanced Verification:**  Platforms must use "reasonable measures" to verify age, which includes but isn't limited to:
    * **Government-Issued ID:** Requiring a driver’s license or other government ID.
    * **Biometric Verification:**  Using facial recognition or other biometric methods.
    * **Educational Records:** Requesting documentation from schools.
    * **Manual Review:**  Employing a team to manually review account requests.


**2. Content Restrictions & Removal:**

* **Harmful Content Detection:** Platforms are required to have systems in place to identify and remove content that is deemed harmful to minors, including:
    * **Sexual Abuse Material:** Explicit depictions of sexual acts.
    * **Child Sexual Abuse Material:**  The most severe category, involving the sexual exploitation of children.
    * **Content Facilitating Abuse:** Content that encourages, facilitates, or encourages the abuse of children.
    * **Content Exploiting Children:** Content that exploits, abuses, or endangers children.
* **Reporting Mechanisms:** Platforms must establish clear and accessible mechanisms for users to report harmful content.
* **Prompt Removal:** Platforms must act “with reasonable diligence” to promptly remove reported harmful content.

**3.  Parental Controls & Transparency:**

* **Parental Controls:** Platforms are required to provide robust parental control features.
* **Transparency Reporting:**  Platforms must submit regular reports to the state detailing their efforts to comply with the law, including:
    * Number of accounts created by minors.
    * Number of reports of harmful content received.
    * Number of accounts identified as belonging to minors.
    * Actions taken to remove harmful content.



**4.  Penalties & Enforcement:**

* **Civil Penalties:**  Platforms that violate the law can be subject to significant civil penalties, up to $5,000 per violation.
* **Criminal Penalties:**  In cases of gross negligence or willful disregard for the law, criminal charges may be filed.
* **Attorney General Oversight:** The Florida Attorney General has the authority to investigate and enforce the law.

**Important Notes & Caveats:**

* **“Reasonable Measures” is Key:** The law relies heavily on the term “reasonable measures.” This is open to interpretation and will likely be litigated.
* **Federal Law:** This Florida law is happening *in addition to* federal efforts (like the Kids Online Privacy Protection Act – KOPA) to regulate children’s online privacy and safety.
* **Ongoing Developments:** This law is relatively new, and its implementation and interpretation will continue to evolve.

**Resources for More Information:**

* **Florida Department of Law and Public Safety:** [https://www.fdle.state.fl.us/news-releases/florida-attorney-general-announces-new-law-to-protect-minors-online/](https://www.fdle.state.fl.us/news-releases/florida-attorney-general-announces-new-law-to-protect-minors-online/)
* **Florida Statutes – Chapter 784:** [https://www.flsenate.gov/statutes/chapter/784](https://www.flsenate.gov/statutes/chapter/784)


Do you want me to delve deeper into a specific aspect of this law, such as:

*   The definition of "harmful content"?
*   How the law impacts specific platforms?
*   The potential legal challenges to the law?