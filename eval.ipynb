{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# API key\n",
    "GOOGLE_API_KEY = \"AIzaSyDioCk3CkTGyniXVYGY6cP3d_cpWtIzYdk\"  # Replace with your actual API key\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "\n",
    "class GeminiFlash(DeepEvalBaseLLM):\n",
    "    \"\"\"Class to implement Vertex AI for DeepEval\"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        response = chat_model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"gemini-2.0-flash\"\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# initialize the  wrapper class\n",
    "gemini = GeminiFlash(model=model)\n",
    "# print(gemini.generate(\"Write me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b59ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.dataset import EvaluationDataset, Golden\n",
    "\n",
    "# Test Case with a correctness score of 1 (complete alignment with expected output)\n",
    "first_test_case = LLMTestCase(input=\"Summarize the benefits of daily exercise.\",\n",
    "                              actual_output=\"Daily exercise improves cardiovascular health, boosts mood, and enhances overall fitness.\",\n",
    "                              expected_output=\"Daily exercise improves cardiovascular health, boosts mood, and enhances overall fitness.\")\n",
    "\n",
    "# Test Case with a correctness score of 0.5 (partial alignment with expected output)\n",
    "second_test_case = LLMTestCase(input=\"Explain the process of photosynthesis.\",\n",
    "                               actual_output=\"Photosynthesis is how plants make their food using sunlight.\",\n",
    "                               expected_output=\"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize nutrients from carbon dioxide and water. It involves the green pigment chlorophyll and generates oxygen as a byproduct.\")\n",
    "\n",
    "# Test Case with a correctness score of 0 (no meaningful alignment with expected output)\n",
    "third_test_case = LLMTestCase(input=\"Describe the effects of global warming.\",\n",
    "                              actual_output=\"Global warming leads to colder winters.\",\n",
    "                              expected_output=\"Global warming causes more extreme weather, including hotter summers, rising sea levels, and increased frequency of extreme weather events.\")\n",
    "\n",
    "test_cases = [first_test_case, second_test_case, third_test_case]\n",
    "\n",
    "dataset = EvaluationDataset()\n",
    "for tc in test_cases:\n",
    "    dataset.add_test_case(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2914dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import GEval\n",
    "from deepeval import evaluate\n",
    "\n",
    "correctness_metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    model=gemini,\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the actual output is factually correct based on the expected output.\"\n",
    "    ],    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92197dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Correctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mCorrectness \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a85560a6184f5f96f6fb85e6dbc3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Correctness [GEval] (score: 1.0, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The actual output is identical to the expected output, indicating perfect factual accuracy., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Summarize the benefits of daily exercise.\n",
      "  - actual output: Daily exercise improves cardiovascular health, boosts mood, and enhances overall fitness.\n",
      "  - expected output: Daily exercise improves cardiovascular health, boosts mood, and enhances overall fitness.\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Correctness [GEval] (score: 0.5, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The actual output gives a basic definition of photosynthesis but omits key details present in the expected output. It doesn't mention carbon dioxide, water, chlorophyll, or oxygen, making it factually incomplete compared to the expected output. Therefore, the actual output is only partially correct., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Explain the process of photosynthesis.\n",
      "  - actual output: Photosynthesis is how plants make their food using sunlight.\n",
      "  - expected output: Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize nutrients from carbon dioxide and water. It involves the green pigment chlorophyll and generates oxygen as a byproduct.\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness [GEval] (score: 0.0, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The actual output states that global warming leads to colder winters, which is not factually correct according to the expected output. The expected output specifies that global warming causes more extreme weather, including hotter summers and rising sea levels., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Describe the effects of global warming.\n",
      "  - actual output: Global warming leads to colder winters.\n",
      "  - expected output: Global warming causes more extreme weather, including hotter summers, rising sea levels, and increased frequency of extreme weather events.\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Correctness [GEval]: 66.67% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Evaluation completed 🎉! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.</span>07s | token cost: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   » Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66.67</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» What to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Evaluation completed 🎉! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m3.\u001b[0m07s | token cost: \u001b[3;35mNone\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "» Test Results \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   » Pass Rate: \u001b[1;36m66.67\u001b[0m% | Passed: \u001b[1;32m2\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» What to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepeval.evaluate import AsyncConfig\n",
    "\n",
    "evaluation_output = evaluate(test_cases=dataset.test_cases,\n",
    "                        metrics=[correctness_metric],\n",
    "                        async_config=AsyncConfig(run_async = False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
